{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataMining Project\n",
    "\n",
    "## Description du projet\n",
    "L'objectif de ce projet est de recommander des cartes Yu Gi Oh en fonction des préférences de l'utilisateur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auteur : **Gorvien Mathis** _étudiant en 4ème année en CLBD_\n",
    "\n",
    "\n",
    "Un grand merci à **Perrichet Theotime** _étudiant en 4ème année en Robotique_ pour son aide précieuse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentification\n",
    "_Pour utiliser l' API publique de Kaggle , vous devez d'abord vous authentifier à l'aide d'un jeton d'API. Depuis l'en-tête du site, cliquez sur votre photo de profil d'utilisateur, puis sur \"Mon compte\" dans le menu déroulant. Cela vous amènera aux paramètres de votre compte sur https://www.kaggle.com/account. Faites défiler jusqu'à la section de la page intitulée API :_\n",
    "\n",
    "_Pour créer un nouveau jeton, cliquez sur le bouton \"Créer un nouveau jeton API\". Cela téléchargera un nouveau jeton d'authentification sur votre machine._\n",
    "\n",
    "_Si vous utilisez l'outil Kaggle CLI, l'outil recherchera ce jeton dans __~/.kaggle/kaggle.json sous Linux__, OSX et d'autres systèmes d'exploitation basés sur UNIX, et dans __C:\\Users<Windows-username>.kaggle\\kaggle.json sous Windows__. Si le jeton n'est pas là, une erreur sera levée. Par conséquent, une fois que vous avez téléchargé le jeton, vous devez le déplacer de votre dossier Téléchargements vers ce dossier._\n",
    "\n",
    "_Si vous utilisez directement l'API Kaggle, l'endroit où vous conservez le jeton n'a pas d'importance, tant que vous êtes en mesure de fournir vos informations d'identification au moment de l'exécution._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the dataset\n",
    "kaggle.api.authenticate()\n",
    "kaggle.api.dataset_download_files('archanghosh/yugioh-database/Yugi_images', path='.', unzip=True, quiet=False, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the csv file to the data folder\n",
    "shutil.move('./Yugi_db_cleaned.csv', './data_csv/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBase creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Create the Yu Gi Oh database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r\"./Yugi_images\" # path to the folder that contains the images\n",
    "\n",
    "# initialize the data dictionary\n",
    "all_metadata = {}\n",
    "color_data={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function allowing to crop the images in order to have more precise Kmeans results\n",
    "def crop_and_resize_card(image_path, output_size=(224, 224)):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Calculate the central square coordinates\n",
    "    height, width, _ = image.shape\n",
    "    min_dim = min(height, width)\n",
    "    x = (width - min_dim) // 2\n",
    "    y = (height - min_dim) // 2\n",
    "    \n",
    "    # Crop the central square\n",
    "    cropped_image = image[y+30:y+min_dim-70, x+50:x+min_dim-50]\n",
    "\n",
    "    # Resize the image to the desired output size\n",
    "    resized_image = cv2.resize(cropped_image, output_size)\n",
    "\n",
    "    return resized_image\n",
    "\n",
    "# Create the folder containing the cropped images\n",
    "if not os.path.exists('./resized_yugioh'):\n",
    "    os.makedirs('./resized_yugioh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle through all the image files in the directory\n",
    "for img_filename in os.listdir(img_dir):\n",
    "    if img_filename.endswith(\".jpg\") or img_filename.endswith(\".png\"):\n",
    "        # build the full path to the image file\n",
    "        img_path = os.path.join(img_dir, img_filename)\n",
    "\n",
    "        # load the image file\n",
    "        with Image.open(img_path) as img:\n",
    "\n",
    "            # extract metadata from the image\n",
    "            img_filename= img.filename\n",
    "            img_format = img.format\n",
    "            img_size = img.size\n",
    "            img_orientation = \"landscape\" if img_size[0] > img_size[1] else \"portrait\"\n",
    "            creation_date =  datetime.fromtimestamp(os.path.getctime(img_path)).strftime('%d/%m/%Y')\n",
    "\n",
    "            # Split the filename on '/' and take the last part\n",
    "            filename = img_filename.split('/')[-1]\n",
    "\n",
    "            # Remove the file extension\n",
    "            filename = filename.split('.')[0]\n",
    "\n",
    "            # Crop the images\n",
    "            resized_image = crop_and_resize_card(img_path)\n",
    "            new_path = os.path.join('./resized_yugioh', filename + '.jpg')\n",
    "            cv2.imwrite(new_path, resized_image)\n",
    "\n",
    "            # Create a dictionary of metadata for this image\n",
    "            metadata = {\n",
    "                \"id\": filename,\n",
    "                \"format\": img_format,\n",
    "                \"size\": img_size,\n",
    "                \"orientation\": img_orientation,\n",
    "                \"creation_date\": creation_date,\n",
    "                \"tags\": \"\"\n",
    "            }\n",
    "\n",
    "            # add the metadata of this image to the dictionary of all metadata\n",
    "            all_metadata[filename] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the metadata to the JSON file\n",
    "with open('database.json', \"w\") as f:\n",
    "    json.dump(all_metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Create the color database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from webcolors import CSS3_NAMES_TO_HEX, hex_to_rgb, rgb_to_hex, hex_to_name\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_color(requested_color):\n",
    "    requested_color = hex_to_rgb(requested_color)\n",
    "    min_colors = {}\n",
    "    for key, value in CSS3_NAMES_TO_HEX.items():\n",
    "        color = hex_to_rgb(value)\n",
    "        red_difference = (color[0] - requested_color[0]) ** 2\n",
    "        green_difference = (color[1] - requested_color[1]) ** 2\n",
    "        blue_difference = (color[2] - requested_color[2]) ** 2\n",
    "        difference = red_difference + green_difference + blue_difference\n",
    "        min_colors[difference] = key\n",
    "    return min_colors[min(min_colors.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle through all the image files in the directory\n",
    "color_data = {}\n",
    "img_dir = r\"./resized_yugioh\" # On utilise les images recadrées\n",
    "for img_filename in tqdm(os.listdir(img_dir)): \n",
    "    if img_filename.endswith(\".jpg\") or img_filename.endswith(\".png\"):\n",
    "        # Build the full path to the image file\n",
    "        img_path = os.path.join(img_dir, img_filename)\n",
    "        # Open the image file\n",
    "        with Image.open(img_path) as img:\n",
    "            \n",
    "            pixel_matrix = np.array(img) # Convert the image to a numpy array\n",
    "\n",
    "            # Extract the R, G, B values, even if the image contains more than 3 channels (e.g. RGBA)\n",
    "            if pixel_matrix.shape[2] == 4:\n",
    "                pixel_matrix = pixel_matrix[:, :, :3]\n",
    "\n",
    "            # Convert the pixel matrix to a pixel array\n",
    "            pixel_data = pixel_matrix.reshape((-1, 3))\n",
    "\n",
    "            # Use MiniBatchKMeans to find the largest cluster\n",
    "            kmeans = MiniBatchKMeans(n_clusters=3, random_state=0, n_init=3).fit(pixel_data)\n",
    "            dominant_color = kmeans.cluster_centers_[kmeans.predict([[0, 0, 0]])][0]\n",
    "\n",
    "            # Convert the dominant color to hexadecimal\n",
    "            hex_color = '#{:02x}{:02x}{:02x}'.format(int(dominant_color[0]), int(dominant_color[1]), int(dominant_color[2]))\n",
    "            \n",
    "            # Convert the hexadecimal value to a color name\n",
    "            try:\n",
    "                color_name = hex_to_name(hex_color)\n",
    "            except ValueError:\n",
    "                color_name = closest_color(hex_color)\n",
    "\n",
    "            # Split the filename on '/' and take the last part\n",
    "            filename = img_filename.split('/')[-1]\n",
    "\n",
    "            # Remove the file extension\n",
    "            filename = filename.split('.')[0]\n",
    "\n",
    "            # create a dictionary of color for this image\n",
    "            color = {\n",
    "                \"id\": filename,\n",
    "                \"nom couleur\": color_name\n",
    "            }\n",
    "\n",
    "            # add the color of this image to the dictionary of all colors\n",
    "            color_data[filename] = color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the color to the JSON file\n",
    "with open('color_data.json', 'w') as f:\n",
    "    json.dump(color_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Add colors to Yu Gi Oh cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON files\n",
    "with open('database.json', 'r') as f:\n",
    "    yugioh_data = json.load(f)\n",
    "\n",
    "with open('color_data.json', 'r') as f:\n",
    "    color_data = json.load(f)\n",
    "\n",
    "# If the id of the yugioh card is the same as the id of the color, add the color to the yugioh card\n",
    "for yugioh in yugioh_data:\n",
    "    for color in color_data:\n",
    "        \n",
    "        # Split the filename on '/' and take the last part\n",
    "        filename = yugioh_data[yugioh]['id'].split('/')[-1]\n",
    "\n",
    "        # Remove the file extension\n",
    "        filename = filename.split('.')[0]\n",
    "\n",
    "        if filename == color_data[color]['id']:\n",
    "            yugioh_data[yugioh]['couleur dominante'] = color_data[color]['nom couleur']\n",
    "\n",
    "with open('database.json', 'w') as f:\n",
    "    json.dump(yugioh_data, f, indent=4)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from tags.json into data_d[\"tags\"]\n",
    "df = pd.read_csv(r\"./data_csv/Yugi_db_cleaned.csv\", sep=',', header=0)\n",
    "df_selected = df.loc[:, ['Card_name','Card-set', 'Image_name', 'Rarity', 'Card type', 'Attribute','Types', 'Level']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the column Card_name to Card Name\n",
    "df_selected.rename(columns={'Card_name': 'Card Name'}, inplace=True)\n",
    "\n",
    "# Rename the column Card-set to Card Set\n",
    "df_selected.rename(columns={'Card-set': 'Card Set'}, inplace=True)\n",
    "\n",
    "# Rename the column Image_name to Card Number\n",
    "df_selected.rename(columns={'Image_name': 'Card Number'}, inplace=True)\n",
    "\n",
    "# Replace the .png in the Card Number column with an empty string\n",
    "df_selected['Card Number'] = df_selected['Card Number'].str.replace('.png', '')\n",
    "\n",
    "# Keep only the first value in the Types column\n",
    "df_selected['Types'] = df_selected['Types'].str.split(' / ').str[0]\n",
    "\n",
    "# Rename the column Types to Caracteristic\n",
    "df_selected.rename(columns={'Types': 'Caracteristic'}, inplace=True)\n",
    "\n",
    "with open('tags.json', 'w') as f:\n",
    "    f.write(df_selected.to_json(orient='records')) \n",
    "\n",
    "with open('tags.json', 'r') as f:\n",
    "    data_t = json.load(f)\n",
    "\n",
    "with open('tags.json', 'w') as f:\n",
    "    json.dump(data_t, f, indent=4)\n",
    "\n",
    "with open('database.json', 'r') as f:\n",
    "    data_d = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from tags.json into data_d[\"tags\"]\n",
    "for key in data_d:\n",
    "    for i in range(len(data_t)):\n",
    "\n",
    "        # Split the filename on '/' and take the last part\n",
    "        filename = data_d[key]['id'].split('/')[-1]\n",
    "\n",
    "        if filename == data_t[i][\"Card Number\"]:\n",
    "            data_d[key][\"tags\"] = data_t[i]\n",
    "\n",
    "# Delete the Card Number key from data_d[\"tags\"]\n",
    "for key in data_d:\n",
    "    if data_d[key][\"tags\"] != '':\n",
    "        data_d[key][\"tags\"].pop(\"Card Number\")\n",
    "\n",
    "# Save the data to database.json\n",
    "with open('database.json', 'w') as f:\n",
    "    json.dump(data_d, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create user database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint, choice\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter images according to user preferences\n",
    "def filter_images(images, CardType, Attribute, Rarity, Set):\n",
    "    filtered_images = []\n",
    "    for image in images.values():\n",
    "        if len(image) == 7:\n",
    "            if image[\"tags\"] != '':\n",
    "                color = image[\"couleur dominante\"]\n",
    "                type = image[\"tags\"][\"Card type\"]\n",
    "                attribute = image[\"tags\"][\"Attribute\"]\n",
    "                rarity = image[\"tags\"][\"Rarity\"]\n",
    "                set = image[\"tags\"][\"Card Set\"]\n",
    "                tags= image[\"tags\"]\n",
    "\n",
    "                # Verify that the image matches the user preferences\n",
    "                if (set == Set) and (attribute == Attribute) and (type == CardType) and (rarity == Rarity):\n",
    "                    tags[\"color\"]=color\n",
    "                    filtered_images.append(tags)\n",
    "    return filtered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get color name, card type, attribute, rarity, caracteristic and set from the user\n",
    "\n",
    "data_t={}\n",
    "with open(\"database.json\", \"r\") as f:\n",
    "    data=json.load(f)\n",
    "    for i in data:\n",
    "        data_t[data[i][\"id\"]]=data[i]\n",
    "\n",
    "Type_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Card type\"] not in Type_t:\n",
    "            Type_t.append(data_t[i][\"tags\"][\"Card type\"])\n",
    "\n",
    "Attribute_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Attribute\"] not in Attribute_t:\n",
    "            Attribute_t.append(data_t[i][\"tags\"][\"Attribute\"])\n",
    "\n",
    "Rarity_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Rarity\"] not in Rarity_t:\n",
    "            Rarity_t.append(data_t[i][\"tags\"][\"Rarity\"])\n",
    "\n",
    "Set_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Card Set\"] not in Set_t:\n",
    "            Set_t.append(data_t[i][\"tags\"][\"Card Set\"])\n",
    "\n",
    "\n",
    "Caracteristic_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Caracteristic\"] not in Caracteristic_t:\n",
    "            Caracteristic_t.append(data_t[i][\"tags\"][\"Caracteristic\"])\n",
    "\n",
    "Level_t=[]\n",
    "for i in data_t:\n",
    "    if data_t[i][\"tags\"] != '':\n",
    "        if data_t[i][\"tags\"][\"Level\"] not in Level_t:\n",
    "            Level_t.append(data_t[i][\"tags\"][\"Level\"])\n",
    "\n",
    "# Get the color name from database.json\n",
    "color_t=[]\n",
    "for i in data_t:\n",
    "    if len(data_t[i]) == 7:\n",
    "        if data_t[i][\"couleur dominante\"] not in color_t:\n",
    "            color_t.append(data_t[i][\"couleur dominante\"])\n",
    "\n",
    "legendary_t=[True, False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to recommendation.json\n",
    "with open(\"recommendation.json\", \"w\") as f:\n",
    "    json.dump({\"Set\":Set_t, \"Attribute\":Attribute_t, \"Color\":color_t, \"Caracteristic\":Caracteristic_t, \"Rarity\":Rarity_t}, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate the user's preferences\n",
    "\n",
    "favorite_t=[\"NoFavorite\", \"Favorite\"]\n",
    "all_user={}\n",
    "nb_user=100\n",
    "i=0\n",
    "\n",
    "while i<nb_user:\n",
    "    result=[]\n",
    "    Type=choice(Type_t) \n",
    "    Attribute=choice(Attribute_t) \n",
    "    Rarity=choice(Rarity_t) \n",
    "    Set=choice(Set_t) \n",
    "    Caracteristic=choice(Caracteristic_t) \n",
    "    Level=choice(Level_t) \n",
    "    data=filter_images(data_t, Type, Attribute, Rarity, Set)\n",
    "    if len(data)>0:\n",
    "        for k in range(len(data)): # choose favorite or not\n",
    "            result.append(favorite_t[randint(0, len(favorite_t)-1)])\n",
    "        all_user[i]={\"data\":data, \"result\":result}\n",
    "        i+=1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pok=[]\n",
    "like=[]\n",
    "\n",
    "# create a dictionary with the data and the results\n",
    "for i in all_user:\n",
    "    for k in range(len(all_user[i][\"data\"])):\n",
    "        pok.append(all_user[i][\"data\"][k])\n",
    "        like.append(all_user[i][\"result\"][k])\n",
    "\n",
    "user={\"data\":pok, \"result\":like}\n",
    "\n",
    "# count the number of favorite and not favorite\n",
    "nb_favorite=0\n",
    "nb_nofavorite=0\n",
    "for i in user[\"result\"]:\n",
    "    if i==\"Favorite\":\n",
    "        nb_favorite+=1\n",
    "    else:\n",
    "        nb_nofavorite+=1\n",
    "\n",
    "print(len(user[\"result\"]))\n",
    "print(\"nb_favorite: \", nb_favorite)\n",
    "print(\"nb_nofavorite: \", nb_nofavorite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to user.json\n",
    "with open(\"user.json\", \"w\") as f:\n",
    "    json.dump(user, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the user's data\n",
    "with open('user.json', \"r\") as f:\n",
    "        user=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree creation\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Label encoding creation\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "le8 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.1 Create the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "data = user[\"data\"]\n",
    "result = user[\"result\"]\n",
    "dataframe = pd.DataFrame(data, columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "Type=choice(Type_t) \n",
    "Attribute=choice(Attribute_t) \n",
    "Rarity=choice(Rarity_t) \n",
    "Set=choice(Set_t) \n",
    "Caracteristic=choice(Caracteristic_t) \n",
    "Level=choice(Level_t)\n",
    "\n",
    "# Data encoding\n",
    "dataframe[\"Type\"] = le1.fit_transform(dataframe[\"Type\"])\n",
    "dataframe[\"Attribute\"] = le2.fit_transform(dataframe[\"Attribute\"])\n",
    "dataframe[\"Card-set\"] = le3.fit_transform(dataframe[\"Card-set\"])\n",
    "dataframe[\"Rarity\"] = le4.fit_transform(dataframe[\"Rarity\"])\n",
    "dataframe[\"Caracteristic\"] = le5.fit_transform(dataframe[\"Caracteristic\"])\n",
    "dataframe[\"Level\"] = le6.fit_transform(dataframe[\"Level\"])\n",
    "dataframe[\"color\"] = le7.fit_transform(dataframe[\"color\"])\n",
    "resultframe[\"favorite\"] = le8.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "# Train the model\n",
    "dtc.fit(dataframe, resultframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.2 Model Vizualisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree visualization\n",
    "dot_data = tree.export_graphviz(\n",
    "    dtc,\n",
    "    out_file=None,\n",
    "    feature_names=dataframe.columns,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    class_names=le8.inverse_transform(resultframe.favorite.unique()),\n",
    "    special_characters=True,\n",
    ")\n",
    "graph = graphviz.Source(dot_data)\n",
    "\n",
    "pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "img = Image(pydot_graph.create_png())\n",
    "display(img) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __A.3 Evaluate the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy\n",
    "print(\"Accuracy:\",metrics.accuracy_score(resultframe, dtc.predict(dataframe)))\n",
    "\n",
    "# F1 score of the model\n",
    "print(\"F1 score:\",metrics.f1_score(resultframe, dtc.predict(dataframe)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "y_pred = dtc.predict(dataframe)\n",
    "\n",
    "# Creating confusion matrix\n",
    "cm = confusion_matrix(resultframe, y_pred, normalize='true')\n",
    "    \n",
    "# Displaying confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not favorite', 'favorite'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Save the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(dtc, open(\"decision_tree.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.1 Create the Model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import json\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import plot_tree\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the user's data\n",
    "with open('user.json', 'r') as f:\n",
    "    user_data = json.load(f)\n",
    "\n",
    "# Label encoding creation\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "le8 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe creation\n",
    "data = user_data[\"data\"]\n",
    "result = user_data[\"result\"]\n",
    "dataframe = pd.DataFrame(data, columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "resultframe = pd.DataFrame(result, columns=[\"favorite\"])\n",
    "\n",
    "# Data encoding\n",
    "dataframe[\"Type\"] = le1.fit_transform(dataframe[\"Type\"])\n",
    "dataframe[\"Attribute\"] = le2.fit_transform(dataframe[\"Attribute\"])\n",
    "dataframe[\"Card-set\"] = le3.fit_transform(dataframe[\"Card-set\"])\n",
    "dataframe[\"Rarity\"] = le4.fit_transform(dataframe[\"Rarity\"])\n",
    "dataframe[\"Caracteristic\"] = le5.fit_transform(dataframe[\"Caracteristic\"])\n",
    "dataframe[\"Level\"] = le6.fit_transform(dataframe[\"Level\"])\n",
    "dataframe[\"color\"] = le7.fit_transform(dataframe[\"color\"])\n",
    "resultframe[\"favorite\"] = le8.fit_transform(resultframe[\"favorite\"])\n",
    "\n",
    "# Split the data into training and test data\n",
    "train_data = dataframe.sample(frac=0.8, random_state=0)\n",
    "test_data = dataframe.drop(train_data.index)\n",
    "\n",
    "# split the labels into training and test labels\n",
    "train_labels = resultframe.sample(frac=0.8, random_state=0)\n",
    "test_labels = resultframe.drop(train_labels.index)\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(n_estimators=7, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.2 Model Vizualisation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model.estimators_[0], filled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __B.3 Evaluate the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model accuracy\n",
    "y_pred = model.predict(train_data)\n",
    "print(\"Accuracy:\", accuracy_score(train_labels, y_pred))\n",
    "\n",
    "# F1 score of the model\n",
    "print(\"F1 score:\", f1_score(train_labels, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying confusion matrix\n",
    "cm = confusion_matrix(train_labels, y_pred, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['not favorite', 'favorite'])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Save the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "pickle.dump(model, open(\"random_forest.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisation(tag,value_tag):\n",
    "    # Load the data from the JSON file\n",
    "    with open(\"database.json\") as f:\n",
    "        data = json.load(f)\n",
    "    # Convert the data to a pandas DataFrame\n",
    "    df = pd.DataFrame.from_dict(data, orient='index')\n",
    "\n",
    "    # Unpack the \"tags\" dictionary into columns\n",
    "    df = pd.concat([df.drop('tags', axis=1), df['tags'].apply(pd.Series)], axis=1)\n",
    "\n",
    "    # Group the DataFrame by \"Type 1\"\n",
    "    grouped = df.groupby(tag)\n",
    "\n",
    "    # Print the size of each group\n",
    "    ax=grouped.size().plot(kind=\"bar\", title=f\"Nombre d'images par {tag}\")\n",
    "    # Color the bar(s) corresponding to the value_tag in red\n",
    "    for i, label in enumerate(ax.get_xticklabels()):\n",
    "        if label.get_text() == value_tag:\n",
    "            ax.patches[i].set_color('yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_yugioh():\n",
    "    satisfait = False # Variable de controle de la boucle\n",
    "\n",
    "    # import data\n",
    "    with open('database.json', 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open('recommendation.json', 'r') as f:\n",
    "        rec= json.load(f)\n",
    "\n",
    "    # import model\n",
    "    random_forest = pickle.load(open(\"random_forest.pkl\", \"rb\"))\n",
    "    decision_tree = pickle.load(open(\"decision_tree.pkl\", \"rb\"))\n",
    "\n",
    "    # Label encoding creation\n",
    "    le1 = LabelEncoder()\n",
    "    le2 = LabelEncoder()\n",
    "    le3 = LabelEncoder()\n",
    "    le4 = LabelEncoder()\n",
    "    le5 = LabelEncoder()\n",
    "    le6 = LabelEncoder()\n",
    "    le7 = LabelEncoder()\n",
    "\n",
    "    recommandations = []\n",
    "    \n",
    "\n",
    "    while not satisfait:\n",
    "\n",
    "        # User input\n",
    "        print(\"Hello, I am a yugioh assistant, I will help you choose your next yu gi oh card\")\n",
    "        type = input(\"What is the type you like the most: Monster, Trap or Spell ? \")\n",
    "        attribute = input(\"What is the attribute you like the most: \" + str(rec[\"Attribute\"]) + \" ? \")\n",
    "        card_set = input(\"What is the card_set you like the most: \" + str(rec[\"Set\"]) + \" ? \")\n",
    "        rarity = input(\"What is the rarity you like the most: \" + str(rec[\"Rarity\"]) + \" ? \")\n",
    "        caracteristic = input(\"What is the caracteristic you like the most: \" + str(rec[\"Caracteristic\"]) + \" ? \")\n",
    "        level = input(\"What is the level you like the most: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 ? \")\n",
    "        couleur = input(\"What is the color you like the most: \" + str(rec[\"Color\"]) + \" ? \")\n",
    "\n",
    "        # # Random input\n",
    "        # type = 'Monster'\n",
    "        # attribute = random.choice(rec[\"Attribute\"])\n",
    "        # card_set = random.choice(rec[\"Set\"])\n",
    "        # rarity = random.choice(rec[\"Rarity\"])\n",
    "        # caracteristic = random.choice(rec[\"Caracteristic\"])\n",
    "        # level = 4\n",
    "        # couleur = random.choice(rec[\"Color\"])\n",
    "\n",
    "        dataframe = pd.DataFrame([[type, attribute, card_set, caracteristic, level, couleur, rarity]], columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "\n",
    "        # Data encoding\n",
    "        dataframe[\"Type\"] = le1.fit_transform(dataframe[\"Type\"])\n",
    "        dataframe[\"Attribute\"] = le2.fit_transform(dataframe[\"Attribute\"])\n",
    "        dataframe[\"Card-set\"] = le3.fit_transform(dataframe[\"Card-set\"])\n",
    "        dataframe[\"Rarity\"] = le4.fit_transform(dataframe[\"Rarity\"])\n",
    "        dataframe[\"Caracteristic\"] = le5.fit_transform(dataframe[\"Caracteristic\"])\n",
    "        dataframe[\"Level\"] = le6.fit_transform(dataframe[\"Level\"])\n",
    "        dataframe[\"color\"] = le7.fit_transform(dataframe[\"color\"])\n",
    "            \n",
    "        # Prediction\n",
    "        prediction1 = random_forest.predict(dataframe)\n",
    "        prediction3 = decision_tree.predict(dataframe)\n",
    "\n",
    "        # If 2 of the 3 models predict that the Yu Gi Oh card will be favorite, then the Yu Gi Oh card will be favorite\n",
    "        if (prediction1[0] == 0 or prediction3[0] == 0):\n",
    "            print(\"The card will be favorite\")\n",
    "\n",
    "            # Add the recommended Yu Gi Oh cards to recommandations\n",
    "            for yugioh_data in data.values():\n",
    "                if yugioh_data[\"tags\"] != '':\n",
    "                    if (yugioh_data[\"couleur dominante\"] == couleur or\n",
    "                        ((yugioh_data[\"tags\"][\"Card type\"] == type or\n",
    "                        yugioh_data[\"tags\"][\"Attribute\"] == attribute or\n",
    "                        yugioh_data[\"tags\"][\"Card Set\"] == card_set or\n",
    "                        yugioh_data[\"tags\"][\"Rarity\"] == caracteristic or\n",
    "                        yugioh_data[\"tags\"][\"Caracteristic\"] == caracteristic or\n",
    "                        yugioh_data[\"tags\"][\"Level\"] == level))) :\n",
    "                        recommandations.append(yugioh_data)\n",
    "                    else:\n",
    "                        if (yugioh_data[\"couleur dominante\"] == couleur and\n",
    "                            yugioh_data[\"tags\"][\"Card Set\"] == card_set):\n",
    "                            recommandations.append(yugioh_data)        \n",
    "            satisfait = True\n",
    "        else:\n",
    "            # Else, restart\n",
    "            print(\"The Yu Gi Oh card will not be favorite\")\n",
    "            satisfait = False\n",
    "\n",
    "    # Display the recommended Yu Gi Oh cards\n",
    "    card_limit = 3\n",
    "    counter = 0\n",
    "    print(\"The recommended Yu Gi Oh cards are:\")\n",
    "    if recommandations==[]:\n",
    "        print(\"No Yu Gi Oh card corresponds to your criteria\")\n",
    "    else:\n",
    "        for i in range(3):\n",
    "\n",
    "            yugioh = random.choice(recommandations)\n",
    "            \n",
    "            # find images using the name of the card to find the id\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            img = Image.open(\"./Yugi_images/\" + str(yugioh['id']) + \".png\")\n",
    "            \n",
    "            counter += 1\n",
    "            if yugioh[\"tags\"] != '':\n",
    "                if yugioh[\"tags\"][\"Card type\"] == 'Monster':\n",
    "                    if yugioh[\"tags\"][\"Level\"] != None:\n",
    "                        text = \"Nom: \" + yugioh[\"tags\"][\"Card Name\"] + \"\\nType :\" + yugioh[\"tags\"][\"Attribute\"] +  \"\\nCard-set: \" + yugioh[\"tags\"][\"Card Set\"] + \"\\nrarity: \" + yugioh[\"tags\"][\"Rarity\"] + \"\\nCaracteristic: \" + yugioh[\"tags\"][\"Caracteristic\"] + \"\\nLevel: \" + str(yugioh[\"tags\"][\"Level\"]) + \"\\nCouleur dominante: \" + yugioh[\"couleur dominante\"]\n",
    "                    else:\n",
    "                        text = \"Nom: \" + yugioh[\"tags\"][\"Card Name\"] + \"\\nType :\" + yugioh[\"tags\"][\"Attribute\"] +  \"\\nCard-set: \" + yugioh[\"tags\"][\"Card Set\"] + \"\\nrarity: \" + yugioh[\"tags\"][\"Rarity\"] + \"\\nCaracteristic: \" + yugioh[\"tags\"][\"Caracteristic\"] + \"\\nCouleur dominante: \" + yugioh[\"couleur dominante\"]\n",
    "                else :\n",
    "                    text = \"Nom: \" + yugioh[\"tags\"][\"Card Name\"] + \"\\nType :\" + yugioh[\"tags\"][\"Card type\"] +  \"\\nCard-set: \" + \"\\nrarity: \" + yugioh[\"tags\"][\"Rarity\"] + yugioh[\"tags\"][\"Card Set\"] + \"\\nCouleur dominante: \" + yugioh[\"couleur dominante\"]\n",
    "            else:\n",
    "                print\n",
    "                text = \"Nom: \" + yugioh[\"tags\"][\"Card Name\"] + \"\\nCouleur dominante: \" + \"\\nrarity: \" + yugioh[\"tags\"][\"Rarity\"] + yugioh[\"couleur dominante\"]\n",
    "\n",
    "            axes[0].imshow(img)\n",
    "            axes[1].text(0.5, 0.5,text,fontsize=14, ha='center', va='center')\n",
    "            axes[0].axis('off')\n",
    "            axes[1].axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            if yugioh[\"tags\"] != '':\n",
    "                visualisation(\"Card type\",yugioh[\"tags\"][\"Card type\"])\n",
    "                plt.show()\n",
    "                if yugioh[\"tags\"][\"Card type\"] == 'Monster':\n",
    "                    if yugioh[\"tags\"][\"Level\"] != None:\n",
    "                        visualisation(\"Level\",yugioh[\"tags\"][\"Level\"])\n",
    "                        plt.show()\n",
    "                    visualisation(\"Attribute\",yugioh[\"tags\"][\"Attribute\"])\n",
    "                    plt.show()\n",
    "                    visualisation(\"Caracteristic\",yugioh[\"tags\"][\"Caracteristic\"])\n",
    "                    plt.show()\n",
    "                visualisation(\"Rarity\",yugioh[\"tags\"][\"Rarity\"])\n",
    "                plt.show()\n",
    "                visualisation(\"couleur dominante\",yugioh[\"couleur dominante\"])\n",
    "                plt.show()\n",
    "\n",
    "            if counter == card_limit:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommend_yugioh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test des 2 modèles sur 3 cartes\n",
    "\n",
    "# {'id': 'JOTL-EN053 R', 'format': 'PNG', 'size': [385, 568], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Number 102: Star Seraph Sentry', 'Card Set': 'Judgment of the Light', 'Rarity': 'Rare', 'Card type': 'Monster', 'Attribute': 'LIGHT', 'Caracteristic': 'Fairy', 'Level': None}, 'couleur dominante': 'dimgrey'}\n",
    "# {'id': 'CRMS-EN088 SR', 'format': 'PNG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Code A Ancient Ruins', 'Card Set': 'Crimson Crisis', 'Rarity': 'Super Rare', 'Card type': 'Spell', 'Attribute': None, 'Caracteristic': None, 'Level': None}, 'couleur dominante': 'darkslategrey'}\n",
    "# {'id': 'LODT-EN001 ScR', 'format': 'PNG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Honest', 'Card Set': 'Light of Destruction', 'Rarity': 'Secret Rare', 'Card type': 'Monster', 'Attribute': 'LIGHT', 'Caracteristic': 'Fairy', 'Level': 4.0}, 'couleur dominante': 'darkolivegreen'}\n",
    "# {'id': 'MRD-056 R', 'format': 'PNG', 'size': [475, 681], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Fake Trap', 'Card Set': 'Metal Raiders', 'Rarity': 'Rare', 'Card type': 'Trap', 'Attribute': None, 'Caracteristic': None, 'Level': None}, 'couleur dominante': 'darkslategrey'}\n",
    "# {'id': 'STON-EN007 C', 'format': 'JPEG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'The Six Samurai - Yaichi', 'Card Set': 'Strike of Neos', 'Rarity': 'Common', 'Card type': 'Monster', 'Attribute': 'WATER', 'Caracteristic': 'Warrior', 'Level': 3.0}, 'couleur dominante': 'darkslategrey'}\n",
    "# {'id': 'PGD-049 C', 'format': 'JPEG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Trap Dustshoot', 'Card Set': 'Pharaonic Guardian', 'Rarity': 'Common', 'Card type': 'Trap', 'Attribute': None, 'Caracteristic': None, 'Level': None}, 'couleur dominante': 'black'}\n",
    "# {'id': 'EXVC-EN031 C', 'format': 'JPEG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Karakuri Ninja mdl 7749 \"Nanashick\"', 'Card Set': 'Extreme Victory', 'Rarity': 'Common', 'Card type': 'Monster', 'Attribute': 'EARTH', 'Caracteristic': 'Machine', 'Level': 5.0}, 'couleur dominante': 'darkslategrey'}\n",
    "# {'id': 'AST-016 R', 'format': 'PNG', 'size': [400, 580], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Avatar of The Pot', 'Card Set': 'Ancient Sanctuary', 'Rarity': 'Rare', 'Card type': 'Monster', 'Attribute': 'EARTH', 'Caracteristic': 'Rock', 'Level': 3.0}, 'couleur dominante': 'darkolivegreen'}\n",
    "# {'id': 'CHIM-EN074 R', 'format': 'PNG', 'size': [475, 694], 'orientation': 'portrait', 'creation_date': '16/03/2023', 'tags': {'Card Name': 'Blessed Winds', 'Card Set': 'Chaos Impact', 'Rarity': 'Rare', 'Card type': 'Trap', 'Attribute': None, 'Caracteristic': None, 'Level': None}, 'couleur dominante': 'dimgrey'}\n",
    "\n",
    "\n",
    "# On choisit 3 cartes au hasard\n",
    "carte1 = {'Type': 'Monster', 'Attribute': 'LIGHT', 'Card-set': 'Judgment of the Light', 'Caracteristic': 'Fairy', 'Level': None, 'color': 'dimgrey', 'Rarity': 'Rare'}\n",
    "carte2 = {'Type': 'Spell', 'Attribute': None, 'Card-set': 'Crimson Crisis', 'Caracteristic': None, 'Level': None, 'color': 'darkslategrey', 'Rarity': 'Super Rare'}\n",
    "carte3 = {'Type': 'Monster', 'Attribute': 'EARTH', 'Card-set': 'Sanctuary', 'Caracteristic': 'Rock', 'Level': 4.0, 'color': 'darkolivegreen', 'Rarity': 'Rare '}\n",
    "\n",
    "# Créer un dataframe pour le nouveau Pokémon\n",
    "yugioh = pd.DataFrame([carte1], columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "yugioh2 = pd.DataFrame([carte2], columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "yugioh3 = pd.DataFrame([carte3], columns=[\"Type\", \"Attribute\", \"Card-set\", \"Caracteristic\", \"Level\", \"color\", \"Rarity\"])\n",
    "\n",
    "# Label encoding creation\n",
    "le1 = LabelEncoder()\n",
    "le2 = LabelEncoder()\n",
    "le3 = LabelEncoder()\n",
    "le4 = LabelEncoder()\n",
    "le5 = LabelEncoder()\n",
    "le6 = LabelEncoder()\n",
    "le7 = LabelEncoder()\n",
    "\n",
    "# Encoder les données\n",
    "yugioh[\"Type\"] = le1.fit_transform(yugioh[\"Type\"])\n",
    "yugioh[\"Attribute\"] = le2.fit_transform(yugioh[\"Attribute\"])\n",
    "yugioh[\"Card-set\"] = le3.fit_transform(yugioh[\"Card-set\"])\n",
    "yugioh[\"Rarity\"] = le4.fit_transform(yugioh[\"Rarity\"])\n",
    "yugioh[\"Caracteristic\"] = le5.fit_transform(yugioh[\"Caracteristic\"])\n",
    "yugioh[\"Level\"] = le6.fit_transform(yugioh[\"Level\"])\n",
    "yugioh[\"color\"] = le7.fit_transform(yugioh[\"color\"])\n",
    "\n",
    "yugioh2[\"Type\"] = le1.fit_transform(yugioh2[\"Type\"])\n",
    "yugioh2[\"Attribute\"] = le2.fit_transform(yugioh2[\"Attribute\"])\n",
    "yugioh2[\"Card-set\"] = le3.fit_transform(yugioh2[\"Card-set\"])\n",
    "yugioh2[\"Rarity\"] = le4.fit_transform(yugioh2[\"Rarity\"])\n",
    "yugioh2[\"Caracteristic\"] = le5.fit_transform(yugioh2[\"Caracteristic\"])\n",
    "yugioh2[\"Level\"] = le6.fit_transform(yugioh2[\"Level\"])\n",
    "yugioh2[\"color\"] = le7.fit_transform(yugioh2[\"color\"])\n",
    "\n",
    "yugioh3[\"Type\"] = le1.fit_transform(yugioh3[\"Type\"])\n",
    "yugioh3[\"Attribute\"] = le2.fit_transform(yugioh3[\"Attribute\"])\n",
    "yugioh3[\"Card-set\"] = le3.fit_transform(yugioh3[\"Card-set\"])\n",
    "yugioh3[\"Rarity\"] = le4.fit_transform(yugioh3[\"Rarity\"])\n",
    "yugioh3[\"Caracteristic\"] = le5.fit_transform(yugioh3[\"Caracteristic\"])\n",
    "yugioh3[\"Level\"] = le6.fit_transform(yugioh3[\"Level\"])\n",
    "yugioh3[\"color\"] = le7.fit_transform(yugioh3[\"color\"])\n",
    "\n",
    "\n",
    "# importation des modèles\n",
    "random_forest = pickle.load(open(\"random_forest.pkl\", \"rb\"))\n",
    "decision_tree = pickle.load(open(\"decision_tree.pkl\", \"rb\"))\n",
    "\n",
    "# Prédire si le Pokémon sera favori ou non\n",
    "prediction1 = random_forest.predict(yugioh)\n",
    "prediction3 = decision_tree.predict(yugioh)\n",
    "\n",
    "prediction4 = random_forest.predict(yugioh2)\n",
    "prediction6 = decision_tree.predict(yugioh2)\n",
    "\n",
    "prediction7 = random_forest.predict(yugioh3)\n",
    "prediction9 = decision_tree.predict(yugioh3)\n",
    "\n",
    "\n",
    "# Afficher la prédiction\n",
    "print(\"Pour la carte 1 :\")\n",
    "if prediction1[0]==0 :\n",
    "    print(\"d'apres le random forest le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le random forest le Pokémon ne sera pas favori\")\n",
    "\n",
    "if prediction3[0]==0 :\n",
    "    print(\"d'apres le decision tree le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le decision tree le Pokémon ne sera pas favori\")\n",
    "\n",
    "print(\"Pour la carte 2 :\")\n",
    "if prediction4[0]==0 :\n",
    "    print(\"d'apres le random forest le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le random forest le Pokémon ne sera pas favori\")\n",
    "\n",
    "if prediction6[0]==0 :\n",
    "    print(\"d'apres le decision tree le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le decision tree le Pokémon ne sera pas favori\")\n",
    "\n",
    "print(\"Pour la carte 3 :\")\n",
    "if prediction7[0]==0 :\n",
    "    print(\"d'apres le random forest le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le random forest le Pokémon ne sera pas favori\")\n",
    "\n",
    "if prediction9[0]==0 :\n",
    "    print(\"d'apres le decision tree le Pokémon sera favori\")\n",
    "else:\n",
    "    print(\"d'apres le decision tree le Pokémon ne sera pas favori\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e709a68c8bffd8ca64ede960b472aee5cbbab0a7eefe704a97155fcd513aef5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
